{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a9cc037-1a45-4d58-8c71-d8fa391bac32",
   "metadata": {},
   "source": [
    "## Building the Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b4d41b-bfe4-4714-8cc6-96444c422ff2",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d48fb3ec-8349-4b18-afba-9a8fdc2e6d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import logging\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313441a1-5998-4309-b0ab-b9fdb3d30b53",
   "metadata": {},
   "source": [
    "Load and Split data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99103050-f584-43c1-9d13-416871b5dc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a pandas DataFrame\n",
    "data = pd.read_csv('zomato_clean.csv')\n",
    "\n",
    "# Split the data into training and testing sets with stratified sampling\n",
    "train_data, test_data = train_test_split(data, test_size=0.01, random_state=42)\n",
    "\n",
    "# Save the training and testing sets to separate CSV files\n",
    "train_data.to_csv('train_data.csv', index=False)\n",
    "test_data.to_csv('test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4384de5e-d4e2-4e49-ae73-eb07c2f38c3f",
   "metadata": {},
   "source": [
    "Set unwanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54d775d7-503a-4a1d-a234-bf1f5da00387",
   "metadata": {},
   "outputs": [],
   "source": [
    "unwanted_columns = ['name', 'type', 'dish_liked']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61abd94f-7214-4ea9-a6db-0fac0421429c",
   "metadata": {},
   "source": [
    "Write functions for preprocess data, create pipline and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f22b0c98-85aa-4777-b5d7-86affa220391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add logging statement\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def preprocess_data(data, unwanted_columns):\n",
    "    \"\"\"\n",
    "    Preprocess the data.\n",
    "\n",
    "    Parameters:\n",
    "    - data (pandas.DataFrame): The data to be preprocessed.\n",
    "    - unwanted_columns (list): List of unwanted columns to drop.\n",
    "\n",
    "    Returns:\n",
    "    - pandas.DataFrame: The preprocessed data.\n",
    "    \"\"\"\n",
    "    # Drop unwanted columns\n",
    "    data.drop(unwanted_columns, axis=1, inplace=True)\n",
    "\n",
    "    # Drop null values\n",
    "    data.dropna(inplace=True)\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "def create_pipeline():\n",
    "    \"\"\"\n",
    "    Create the pipeline for training an Extra Trees Regressor.\n",
    "\n",
    "    Returns:\n",
    "    - sklearn.pipeline.Pipeline: The pipeline for training the model.\n",
    "    \"\"\"\n",
    "    # Define the columns for different transformations\n",
    "    numeric_columns = ['votes']\n",
    "    binary_columns = ['online_order', 'book_table']\n",
    "    categorical_columns = ['location', 'rest_type', 'cuisines']\n",
    "\n",
    "    # Create pipeline for preprocessing numeric features\n",
    "    numeric_transformer = Pipeline([\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    # Create pipeline for preprocessing binary features\n",
    "    binary_transformer = Pipeline([\n",
    "        ('encoder', OrdinalEncoder())\n",
    "    ])\n",
    "\n",
    "    # Create pipeline for preprocessing categorical features\n",
    "    categorical_transformer = Pipeline([\n",
    "        ('encoder', OrdinalEncoder())\n",
    "    ])\n",
    "\n",
    "    # Combine the transformers using ColumnTransformer\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('numeric_preprocess', numeric_transformer, numeric_columns),\n",
    "        ('binary_preprocess', binary_transformer, binary_columns),\n",
    "        ('categorical_preprocess', categorical_transformer, categorical_columns)\n",
    "    ])\n",
    "\n",
    "    # Create the final pipeline with preprocessor and Extra Trees Regressor\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocess', preprocessor),\n",
    "        ('regressor', ExtraTreesRegressor(n_estimators=120))\n",
    "    ])\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "def train_model(X, Y):\n",
    "    \"\"\"\n",
    "    Train the Extra Trees Regressor model.\n",
    "\n",
    "    Parameters:\n",
    "    - X (pandas.DataFrame): The input features.\n",
    "    - Y (pandas.Series): The target variable.\n",
    "    - test_size (float): The proportion of the dataset to include in the test split.\n",
    "    - random_state (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    - sklearn.pipeline.Pipeline: The trained model.\n",
    "    \"\"\"\n",
    "    # Create the pipeline\n",
    "    pipeline = create_pipeline()\n",
    "\n",
    "    # Fit the pipeline to the training data\n",
    "    pipeline.fit(X, Y)\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005492e9-7abd-4976-8de2-8d9cf5b7a1fc",
   "metadata": {},
   "source": [
    "Create and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d89a2ddc-949b-4951-b32c-8a2e4fd0b377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>online_order</th>\n",
       "      <th>book_table</th>\n",
       "      <th>rate</th>\n",
       "      <th>votes</th>\n",
       "      <th>location</th>\n",
       "      <th>rest_type</th>\n",
       "      <th>cuisines</th>\n",
       "      <th>cost_for_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>4.0</td>\n",
       "      <td>465</td>\n",
       "      <td>Jayanagar</td>\n",
       "      <td>Casual Dining</td>\n",
       "      <td>South Indian, North Indian, Chinese, Street Food</td>\n",
       "      <td>600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>3.8</td>\n",
       "      <td>43</td>\n",
       "      <td>BTM</td>\n",
       "      <td>Quick Bites</td>\n",
       "      <td>South Indian</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>3.8</td>\n",
       "      <td>93</td>\n",
       "      <td>Kaggadasapura</td>\n",
       "      <td>Takeaway, Delivery</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>3.6</td>\n",
       "      <td>216</td>\n",
       "      <td>Thippasandra</td>\n",
       "      <td>Casual Dining</td>\n",
       "      <td>North Indian, South Indian, Chinese, Seafood</td>\n",
       "      <td>550.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3007</td>\n",
       "      <td>Koramangala 1st Block</td>\n",
       "      <td>Cafe</td>\n",
       "      <td>Cafe, Burger, Italian, Salad</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23021</th>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>3.6</td>\n",
       "      <td>74</td>\n",
       "      <td>Koramangala 5th Block</td>\n",
       "      <td>Casual Dining</td>\n",
       "      <td>Bengali</td>\n",
       "      <td>700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23022</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>4.3</td>\n",
       "      <td>74</td>\n",
       "      <td>Residency Road</td>\n",
       "      <td>Cafe</td>\n",
       "      <td>Cafe, Japanese</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23023</th>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>3.9</td>\n",
       "      <td>443</td>\n",
       "      <td>Frazer Town</td>\n",
       "      <td>Casual Dining</td>\n",
       "      <td>Biryani, North Indian, Mughlai</td>\n",
       "      <td>600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23024</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>3.8</td>\n",
       "      <td>177</td>\n",
       "      <td>JP Nagar</td>\n",
       "      <td>Quick Bites</td>\n",
       "      <td>North Indian, Mangalorean, Chinese</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23025</th>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>4.1</td>\n",
       "      <td>205</td>\n",
       "      <td>Koramangala 5th Block</td>\n",
       "      <td>Quick Bites</td>\n",
       "      <td>Fast Food</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23026 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      online_order book_table  rate  votes               location  \\\n",
       "0              Yes         No   4.0    465              Jayanagar   \n",
       "1               No         No   3.8     43                    BTM   \n",
       "2              Yes         No   3.8     93          Kaggadasapura   \n",
       "3              Yes         No   3.6    216           Thippasandra   \n",
       "4              Yes         No   4.1   3007  Koramangala 1st Block   \n",
       "...            ...        ...   ...    ...                    ...   \n",
       "23021          Yes         No   3.6     74  Koramangala 5th Block   \n",
       "23022           No         No   4.3     74         Residency Road   \n",
       "23023          Yes         No   3.9    443            Frazer Town   \n",
       "23024           No         No   3.8    177               JP Nagar   \n",
       "23025          Yes         No   4.1    205  Koramangala 5th Block   \n",
       "\n",
       "                rest_type                                          cuisines  \\\n",
       "0           Casual Dining  South Indian, North Indian, Chinese, Street Food   \n",
       "1             Quick Bites                                      South Indian   \n",
       "2      Takeaway, Delivery                                            Kerala   \n",
       "3           Casual Dining      North Indian, South Indian, Chinese, Seafood   \n",
       "4                    Cafe                      Cafe, Burger, Italian, Salad   \n",
       "...                   ...                                               ...   \n",
       "23021       Casual Dining                                           Bengali   \n",
       "23022                Cafe                                    Cafe, Japanese   \n",
       "23023       Casual Dining                    Biryani, North Indian, Mughlai   \n",
       "23024         Quick Bites                North Indian, Mangalorean, Chinese   \n",
       "23025         Quick Bites                                         Fast Food   \n",
       "\n",
       "       cost_for_2  \n",
       "0           600.0  \n",
       "1           200.0  \n",
       "2           300.0  \n",
       "3           550.0  \n",
       "4          1000.0  \n",
       "...           ...  \n",
       "23021       700.0  \n",
       "23022       400.0  \n",
       "23023       600.0  \n",
       "23024       400.0  \n",
       "23025       250.0  \n",
       "\n",
       "[23026 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c272b7d-a0bd-4ce1-858a-ff5714c5bab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "online_order     object\n",
       "book_table       object\n",
       "rate            float64\n",
       "votes             int64\n",
       "location         object\n",
       "rest_type        object\n",
       "cuisines         object\n",
       "cost_for_2      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55539724-0846-49b3-bb78-df9aefb53633",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-16 18:37:01,511 - INFO - Loading and preprocessing data...\n",
      "2023-07-16 18:37:09,365 - INFO - Model trained and saved.\n"
     ]
    }
   ],
   "source": [
    "# Add logging statement\n",
    "logging.info(\"Loading and preprocessing data...\")\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('train_data.csv')\n",
    "\n",
    "# Splitting data\n",
    "X = data.drop(['rate'], axis=1)\n",
    "Y = data['rate']\n",
    "\n",
    "# Preprocess the data\n",
    "preprocessed_data = preprocess_data(data, unwanted_columns)\n",
    "\n",
    "# Train the model\n",
    "model = train_model(X, Y)\n",
    "\n",
    "# Save the trained model\n",
    "pickle.dump(model, open('model.pkl', 'wb'))\n",
    "\n",
    "# Add logging statement\n",
    "logging.info(\"Model trained and saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d4b767-391d-4078-a490-df5694c5557d",
   "metadata": {},
   "source": [
    "Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c315c85b-8d2b-4174-a7eb-8a0ddb55213d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-16 18:38:57,193 - INFO - Predictions saved to 'predictions.csv'.\n",
      "2023-07-16 18:38:57,195 - INFO - Mean Squared Error (MSE): 0.0001609802345275289\n",
      "2023-07-16 18:38:57,198 - INFO - Mean Absolute Error (MAE): 0.0017049406869671607\n",
      "2023-07-16 18:38:57,199 - INFO - R-squared (R2) Score: 0.9991145481276679\n",
      "2023-07-16 18:38:57,204 - INFO - Report saved to 'report.txt'.\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "pipeline = pickle.load(open('model.pkl', 'rb'))\n",
    "\n",
    "# Load new data for prediction\n",
    "new_data = pd.read_csv('test_data.csv')\n",
    "\n",
    "# Preprocess the new data using the pipeline\n",
    "preprocessed_new_data = preprocess_data(new_data, unwanted_columns)\n",
    "\n",
    "# Predict on the new data\n",
    "predictions = pipeline.predict(preprocessed_new_data)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mse = mean_squared_error(Y, pipeline.predict(X))\n",
    "mae = mean_absolute_error(Y, pipeline.predict(X))\n",
    "r2 = r2_score(Y, pipeline.predict(X))\n",
    "\n",
    "# Save the predictions to a file\n",
    "preprocessed_new_data['predictions'] = predictions\n",
    "preprocessed_new_data.to_csv('predictions.csv', index=False)\n",
    "\n",
    "# Add logging statement\n",
    "logging.info(\"Predictions saved to 'predictions.csv'.\")\n",
    "\n",
    "# Print evaluation metrics\n",
    "logging.info(f\"Mean Squared Error (MSE): {mse}\")\n",
    "logging.info(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "logging.info(f\"R-squared (R2) Score: {r2}\")\n",
    "\n",
    "# Export evaluation metrics and model name to a report file\n",
    "report = f\"Model: Extra Trees Regressor\\n\\n\"\n",
    "report += f\"Mean Squared Error (MSE): {mse}\\n\"\n",
    "report += f\"Mean Absolute Error (MAE): {mae}\\n\"\n",
    "report += f\"R-squared (R2) Score: {r2}\\n\"\n",
    "\n",
    "with open('report.txt', 'w') as file:\n",
    "    file.write(report)\n",
    "\n",
    "# Add logging statement\n",
    "logging.info(\"Report saved to 'report.txt'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
